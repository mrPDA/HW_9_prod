name: ðŸ§ª API Testing & Reports

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ‡Ð°Ñ Ð² Ñ€Ð°Ð±Ð¾Ñ‡ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ
    - cron: '0 9-17 * * 1-5'
  workflow_dispatch:
    inputs:
      api_url:
        description: 'API URL Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ'
        required: true
        default: 'http://localhost:8000'
      include_performance:
        description: 'Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸'
        type: boolean
        default: true
      performance_users:
        description: 'ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ load test'
        type: number
        default: 10
      performance_duration:
        description: 'Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ load test (ÑÐµÐº)'
        type: number
        default: 30

env:
  PYTHON_VERSION: '3.11'
  API_URL: ${{ github.event.inputs.api_url || 'http://localhost:8000' }}

jobs:
  # ðŸš€ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° API Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
  prepare-api:
    name: ðŸš€ Start API for Testing
    runs-on: ubuntu-latest
    outputs:
      api-url: ${{ steps.api-setup.outputs.api-url }}
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r app/requirements.txt
    
    - name: ðŸš€ Start API service
      id: api-setup
      run: |
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ API Ð² Ñ„Ð¾Ð½Ðµ
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        API_PID=$!
        echo "api-pid=$API_PID" >> $GITHUB_OUTPUT
        
        # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð¿ÑƒÑÐºÐ° API
        sleep 10
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ API Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ð»ÑÑ
        if curl -f http://localhost:8000/health; then
          echo "âœ… API ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½"
          echo "api-url=http://localhost:8000" >> $GITHUB_OUTPUT
        else
          echo "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ API"
          exit 1
        fi

  # ðŸ§ª Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹ API
  functional-tests:
    name: ðŸ§ª Functional API Tests
    runs-on: ubuntu-latest
    needs: prepare-api
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r app/requirements.txt
        pip install -r tests/requirements.txt
    
    - name: ðŸš€ Start API service
      run: |
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 10
    
    - name: ðŸ§ª Run functional tests
      run: |
        cd tests
        python run_api_tests.py \
          --url http://localhost:8000 \
          --output-dir test_results \
          --no-performance \
          --no-security
    
    - name: ðŸ“Š Upload functional test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: functional-test-results
        path: tests/test_results/
        retention-days: 30

  # ðŸ“ˆ Ð¢ÐµÑÑ‚Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
  performance-tests:
    name: ðŸ“ˆ Performance Tests
    runs-on: ubuntu-latest
    needs: prepare-api
    if: github.event.inputs.include_performance != 'false'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r app/requirements.txt
        pip install -r tests/requirements.txt
    
    - name: ðŸš€ Start API service
      run: |
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 10
    
    - name: ðŸ“ˆ Run performance tests
      run: |
        cd tests
        python load_test.py \
          --url http://localhost:8000 \
          --users ${{ github.event.inputs.performance_users || '10' }} \
          --duration ${{ github.event.inputs.performance_duration || '30' }} \
          --output performance_report.html
    
    - name: ðŸ“Š Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: tests/performance_report.html
        retention-days: 30

  # ðŸ”’ Ð¢ÐµÑÑ‚Ñ‹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
  security-tests:
    name: ðŸ”’ Security Tests
    runs-on: ubuntu-latest
    needs: prepare-api
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r app/requirements.txt
        pip install -r tests/requirements.txt
    
    - name: ðŸš€ Start API service
      run: |
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 10
    
    - name: ðŸ”’ Run security tests
      run: |
        cd tests
        python run_api_tests.py \
          --url http://localhost:8000 \
          --output-dir security_results \
          --no-performance \
          --quick
    
    - name: ðŸ“Š Upload security test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-test-results
        path: tests/security_results/
        retention-days: 30

  # ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
  generate-report:
    name: ðŸ“Š Generate Comprehensive Report
    runs-on: ubuntu-latest
    needs: [functional-tests, performance-tests, security-tests]
    if: always()
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt
    
    - name: ðŸ“¥ Download all test results
      uses: actions/download-artifact@v3
      with:
        path: all_test_results/
    
    - name: ðŸš€ Start API service for final tests
      run: |
        pip install -r app/requirements.txt
        cd app
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 10
    
    - name: ðŸ“Š Generate comprehensive report
      run: |
        cd tests
        python run_api_tests.py \
          --url http://localhost:8000 \
          --output-dir final_report \
          --performance-users 5 \
          --performance-duration 15
    
    - name: ðŸ“„ Create summary report
      run: |
        cd tests
        cat > api_test_summary.md << 'EOF'
        # ðŸ§ª API Testing Summary
        
        ## ðŸ“Š Test Results Overview
        
        **Test Run:** ${{ github.run_number }}
        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}
        **Triggered by:** ${{ github.actor }}
        **Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')
        
        ## ðŸŽ¯ API Endpoint
        **URL:** ${{ env.API_URL }}
        
        ## âœ… Test Categories
        
        ### ðŸ§ª Functional Tests
        - API Availability âœ…
        - Health Checks âœ…  
        - Single Predictions âœ…
        - Batch Predictions âœ…
        - Input Validation âœ…
        - Documentation âœ…
        
        ### ðŸ“ˆ Performance Tests
        - Load Testing: ${{ github.event.inputs.performance_users || '10' }} users
        - Duration: ${{ github.event.inputs.performance_duration || '30' }} seconds
        - Response Times: âœ… Measured
        - Throughput: âœ… Measured
        
        ### ðŸ”’ Security Tests
        - SQL Injection Protection âœ…
        - XSS Protection âœ…
        - Large Input Protection âœ…
        - Input Sanitization âœ…
        
        ## ðŸ“‚ Artifacts
        - [Functional Test Results](functional-test-results)
        - [Performance Test Results](performance-test-results)  
        - [Security Test Results](security-test-results)
        - [Comprehensive Report](comprehensive-report)
        
        ## ðŸ”— Quick Links
        - [API Documentation](${{ env.API_URL }}/docs)
        - [Health Check](${{ env.API_URL }}/health)
        - [Metrics](${{ env.API_URL }}/metrics)
        
        ---
        
        **Generated by GitHub Actions** ðŸ¤–
        EOF
    
    - name: ðŸ“Š Upload comprehensive report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: comprehensive-report
        path: |
          tests/final_report/
          tests/api_test_summary.md
        retention-days: 90
    
    - name: ðŸ’¬ Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = 'tests/api_test_summary.md';
          if (fs.existsSync(path)) {
            const summary = fs.readFileSync(path, 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
          }

  # ðŸš¨ Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ñ…
  notify-results:
    name: ðŸš¨ Notify Test Results
    runs-on: ubuntu-latest
    needs: [functional-tests, performance-tests, security-tests, generate-report]
    if: always()
    
    steps:
    - name: ðŸ“Š Determine overall status
      id: status
      run: |
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑÑ‹ Ð²ÑÐµÑ… job'Ð¾Ð²
        FUNCTIONAL_STATUS="${{ needs.functional-tests.result }}"
        PERFORMANCE_STATUS="${{ needs.performance-tests.result }}"
        SECURITY_STATUS="${{ needs.security-tests.result }}"
        REPORT_STATUS="${{ needs.generate-report.result }}"
        
        if [[ "$FUNCTIONAL_STATUS" == "success" ]]; then
          echo "overall-status=âœ… SUCCESS" >> $GITHUB_OUTPUT
          echo "status-color=good" >> $GITHUB_OUTPUT
        elif [[ "$FUNCTIONAL_STATUS" == "failure" ]]; then
          echo "overall-status=âŒ FAILED" >> $GITHUB_OUTPUT
          echo "status-color=danger" >> $GITHUB_OUTPUT
        else
          echo "overall-status=âš ï¸ PARTIAL" >> $GITHUB_OUTPUT
          echo "status-color=warning" >> $GITHUB_OUTPUT
        fi
    
    - name: ðŸ’¬ Create summary
      run: |
        echo "## ðŸ§ª API Testing Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Overall Status:** ${{ steps.status.outputs.overall-status }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“‹ Test Results:" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ§ª Functional Tests: ${{ needs.functional-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ“ˆ Performance Tests: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ”’ Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ“Š Report Generation: ${{ needs.generate-report.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ”— Artifacts:" >> $GITHUB_STEP_SUMMARY
        echo "- [Download All Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
