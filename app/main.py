#!/usr/bin/env python3
"""
üöÄ ML Fraud Detection API Service
===================================

Production-ready FastAPI —Å–µ—Ä–≤–∏—Å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞
—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π MLflow Model Registry –∏ Kubernetes.

–ê–≤—Ç–æ—Ä: ML Team
–í–µ—Ä—Å–∏—è: 1.0.0
"""

import os
import sys
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Any

import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from prometheus_client import start_http_server
from pydantic import BaseModel, Field
import pandas as pd

from app.core.config import get_settings
from app.core.logging import setup_logging
from app.models.fraud_detector import FraudDetectionModel
from app.api.health import router as health_router
from app.api.metrics import router as metrics_router

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
setup_logging()
logger = logging.getLogger(__name__)

# Prometheus –º–µ—Ç—Ä–∏–∫–∏
PREDICTION_COUNTER = Counter('ml_predictions_total', 'Total ML predictions made')
PREDICTION_LATENCY = Histogram('ml_prediction_duration_seconds', 'ML prediction latency')
ERROR_COUNTER = Counter('ml_prediction_errors_total', 'Total ML prediction errors')

# –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
settings = get_settings()

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="üõ°Ô∏è Fraud Detection API",
    description="Production ML API –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
ml_model: Optional[FraudDetectionModel] = None


class TransactionRequest(BaseModel):
    """–°—Ö–µ–º–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞"""
    
    transaction_id: str = Field(..., description="–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
    amount: float = Field(..., ge=0, description="–°—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
    merchant_category: str = Field(..., description="–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–æ–¥–∞–≤—Ü–∞")
    hour_of_day: int = Field(..., ge=0, le=23, description="–ß–∞—Å –¥–Ω—è (0-23)")
    day_of_week: int = Field(..., ge=0, le=6, description="–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (0-6)")
    user_age: Optional[int] = Field(None, ge=0, le=120, description="–í–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    location_risk_score: Optional[float] = Field(None, ge=0, le=1, description="–†–∏—Å–∫ –ª–æ–∫–∞—Ü–∏–∏ (0-1)")
    
    class Config:
        schema_extra = {
            "example": {
                "transaction_id": "txn_123456",
                "amount": 150.75,
                "merchant_category": "restaurant",
                "hour_of_day": 14,
                "day_of_week": 2,
                "user_age": 35,
                "location_risk_score": 0.2
            }
        }


class PredictionResponse(BaseModel):
    """–°—Ö–µ–º–∞ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º"""
    
    transaction_id: str
    is_fraud: bool
    fraud_probability: float = Field(..., ge=0, le=1)
    confidence: str
    model_version: str
    prediction_timestamp: datetime
    processing_time_ms: float


class BatchPredictionRequest(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    
    transactions: List[TransactionRequest]
    
    class Config:
        schema_extra = {
            "example": {
                "transactions": [
                    {
                        "transaction_id": "txn_001",
                        "amount": 50.0,
                        "merchant_category": "grocery",
                        "hour_of_day": 10,
                        "day_of_week": 1
                    },
                    {
                        "transaction_id": "txn_002", 
                        "amount": 999.99,
                        "merchant_category": "electronics",
                        "hour_of_day": 23,
                        "day_of_week": 6
                    }
                ]
            }
        }


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–∏—Å–∞"""
    global ml_model
    
    logger.info("üöÄ Starting Fraud Detection API Service...")
    logger.info(f"üìä MLflow URI: {settings.mlflow_tracking_uri}")
    logger.info(f"ü§ñ Model: {settings.model_name}@{settings.model_alias}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å
        ml_model = FraudDetectionModel(
            mlflow_uri=settings.mlflow_tracking_uri,
            model_name=settings.model_name,
            model_alias=settings.model_alias
        )
        
        await ml_model.load_model()
        logger.info("‚úÖ ML model loaded successfully")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º Prometheus metrics —Å–µ—Ä–≤–µ—Ä
        if settings.enable_metrics:
            start_http_server(settings.metrics_port)
            logger.info(f"üìà Prometheus metrics server started on port {settings.metrics_port}")
            
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize service: {e}")
        sys.exit(1)


@app.on_event("shutdown")
async def shutdown_event():
    """Graceful shutdown"""
    logger.info("üîÑ Shutting down Fraud Detection API Service...")


def get_model() -> FraudDetectionModel:
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    if ml_model is None:
        raise HTTPException(
            status_code=503,
            detail="ML model not loaded. Service unavailable."
        )
    return ml_model


@app.post("/predict", response_model=PredictionResponse)
async def predict_fraud(
    request: TransactionRequest,
    background_tasks: BackgroundTasks,
    model: FraudDetectionModel = Depends(get_model)
):
    """
    üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ (0-1)
    - –ë–∏–Ω–∞—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (fraud/not fraud)
    - –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    """
    start_time = time.time()
    PREDICTION_COUNTER.inc()
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ DataFrame
        transaction_data = pd.DataFrame([request.dict()])
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = await model.predict(transaction_data)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_time = (time.time() - start_time) * 1000
        PREDICTION_LATENCY.observe(time.time() - start_time)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = "high" if abs(prediction_result['fraud_probability'] - 0.5) > 0.3 else "medium"
        if abs(prediction_result['fraud_probability'] - 0.5) > 0.4:
            confidence = "very_high"
        
        response = PredictionResponse(
            transaction_id=request.transaction_id,
            is_fraud=prediction_result['is_fraud'],
            fraud_probability=prediction_result['fraud_probability'],
            confidence=confidence,
            model_version=model.model_version,
            prediction_timestamp=datetime.utcnow(),
            processing_time_ms=round(processing_time, 2)
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(
            log_prediction,
            request.transaction_id,
            prediction_result['fraud_probability'],
            confidence
        )
        
        return response
        
    except Exception as e:
        ERROR_COUNTER.inc()
        logger.error(f"‚ùå Prediction error for {request.transaction_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Prediction failed: {str(e)}"
        )


@app.post("/predict/batch")
async def predict_fraud_batch(
    request: BatchPredictionRequest,
    model: FraudDetectionModel = Depends(get_model)
):
    """
    üì¶ Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ 100 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∑–∞ —Ä–∞–∑ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    """
    start_time = time.time()
    
    if len(request.transactions) > 100:
        raise HTTPException(
            status_code=400,
            detail="Batch size too large. Maximum 100 transactions per request."
        )
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        transactions_df = pd.DataFrame([t.dict() for t in request.transactions])
        
        # Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predictions = await model.predict_batch(transactions_df)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
        responses = []
        for i, transaction in enumerate(request.transactions):
            pred = predictions.iloc[i]
            confidence = "high" if abs(pred['fraud_probability'] - 0.5) > 0.3 else "medium"
            
            responses.append(PredictionResponse(
                transaction_id=transaction.transaction_id,
                is_fraud=pred['is_fraud'],
                fraud_probability=pred['fraud_probability'],
                confidence=confidence,
                model_version=model.model_version,
                prediction_timestamp=datetime.utcnow(),
                processing_time_ms=round((time.time() - start_time) * 1000 / len(request.transactions), 2)
            ))
        
        PREDICTION_COUNTER.inc(len(request.transactions))
        PREDICTION_LATENCY.observe(time.time() - start_time)
        
        return {
            "predictions": responses,
            "batch_size": len(responses),
            "total_processing_time_ms": round((time.time() - start_time) * 1000, 2)
        }
        
    except Exception as e:
        ERROR_COUNTER.inc()
        logger.error(f"‚ùå Batch prediction error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Batch prediction failed: {str(e)}"
        )


async def log_prediction(transaction_id: str, fraud_prob: float, confidence: str):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    logger.info(
        f"üéØ Prediction: {transaction_id} | "
        f"Fraud: {fraud_prob:.3f} | "
        f"Confidence: {confidence}"
    )


# –ü–æ–¥–∫–ª—é—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–æ—É—Ç–µ—Ä—ã
app.include_router(health_router, prefix="/health", tags=["Health"])
app.include_router(metrics_router, prefix="/metrics", tags=["Metrics"])


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–µ—Ä–≤–∏—Å–µ"""
    return {
        "service": "üõ°Ô∏è Fraud Detection API",
        "version": "1.0.0",
        "status": "healthy",
        "model": {
            "name": settings.model_name,
            "alias": settings.model_alias,
            "version": ml_model.model_version if ml_model else "not_loaded"
        },
        "endpoints": {
            "predict": "/predict",
            "batch_predict": "/predict/batch", 
            "health": "/health",
            "metrics": "/metrics",
            "docs": "/docs"
        },
        "timestamp": datetime.utcnow().isoformat()
    }


if __name__ == "__main__":
    # –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
