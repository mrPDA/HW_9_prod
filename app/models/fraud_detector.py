"""
ü§ñ Fraud Detection Model
========================

–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏ –∏–∑ MLflow Registry
–¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π.
"""

import asyncio
import time
import pickle
import tempfile
import os
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
import logging

import pandas as pd
import numpy as np
import mlflow
import mlflow.pyfunc
import mlflow.sklearn
from mlflow.tracking import MlflowClient
import structlog

from app.core.logging import log_model_metrics, log_error

logger = structlog.get_logger(__name__)


class FraudDetectionModel:
    """
    üõ°Ô∏è –ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π MLflow
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ó–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –∏–∑ MLflow Registry
    - –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    - Batch –æ–±—Ä–∞–±–æ—Ç–∫—É
    - –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    - –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(
        self, 
        mlflow_uri: str,
        model_name: str,
        model_alias: str = "champion",
        model_stage: str = "Production"
    ):
        self.mlflow_uri = mlflow_uri
        self.model_name = model_name
        self.model_alias = model_alias
        self.model_stage = model_stage
        
        self.model = None
        self.model_version = None
        self.model_metadata = {}
        self.feature_names = []
        self.is_loaded = False
        self.load_time = None
        
        # MLflow client
        self.client = None
        
        logger.info(
            "ü§ñ Initializing FraudDetectionModel",
            mlflow_uri=mlflow_uri,
            model_name=model_name,
            model_alias=model_alias,
            model_stage=model_stage
        )
    
    async def load_model(self) -> None:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ MLflow Registry
        """
        start_time = time.time()
        
        try:
            logger.info("üì• Loading model from MLflow Registry...")
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º MLflow
            mlflow.set_tracking_uri(self.mlflow_uri)
            self.client = MlflowClient(self.mlflow_uri)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            model_info = await self._get_model_info()
            self.model_version = model_info["version"]
            self.model_metadata = model_info["metadata"]
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model_uri = f"models:/{self.model_name}@{self.model_alias}"
            logger.info(f"üì¶ Loading model from URI: {model_uri}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
            self.model = await asyncio.get_event_loop().run_in_executor(
                None,
                mlflow.pyfunc.load_model,
                model_uri
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏—á–∞—Ö
            self.feature_names = self._extract_feature_names()
            
            load_time_ms = (time.time() - start_time) * 1000
            self.load_time = load_time_ms
            self.is_loaded = True
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
            log_model_metrics(
                model_name=self.model_name,
                model_version=self.model_version,
                load_time_ms=load_time_ms,
                model_size_mb=self._estimate_model_size()
            )
            
            logger.info(
                "‚úÖ Model loaded successfully",
                model_version=self.model_version,
                load_time_ms=round(load_time_ms, 2),
                feature_count=len(self.feature_names)
            )
            
        except Exception as e:
            self.is_loaded = False
            log_error(
                error_type="ModelLoadError",
                error_message=f"Failed to load model: {str(e)}",
                context={
                    "model_name": self.model_name,
                    "model_alias": self.model_alias,
                    "mlflow_uri": self.mlflow_uri
                },
                exception=e
            )
            raise
    
    async def _get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –∏–∑ Registry"""
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ –∞–ª–∏–∞—Å—É
            model_version = await asyncio.get_event_loop().run_in_executor(
                None,
                self.client.get_model_version_by_alias,
                self.model_name,
                self.model_alias
            )
            
            return {
                "version": model_version.version,
                "stage": model_version.current_stage,
                "metadata": {
                    "run_id": model_version.run_id,
                    "creation_timestamp": model_version.creation_timestamp,
                    "last_updated_timestamp": model_version.last_updated_timestamp,
                    "description": model_version.description,
                    "tags": {tag.key: tag.value for tag in model_version.tags} if model_version.tags else {}
                }
            }
            
        except Exception as e:
            # Fallback: –ø–æ–∏—Å–∫ –ø–æ —Å—Ç–∞–¥–∏–∏
            logger.warning(f"Alias '{self.model_alias}' not found, trying stage '{self.model_stage}'")
            
            latest_versions = await asyncio.get_event_loop().run_in_executor(
                None,
                self.client.get_latest_versions,
                self.model_name,
                [self.model_stage]
            )
            
            if not latest_versions:
                raise ValueError(f"No model found for {self.model_name} in stage {self.model_stage}")
            
            model_version = latest_versions[0]
            return {
                "version": model_version.version,
                "stage": model_version.current_stage,
                "metadata": {
                    "run_id": model_version.run_id,
                    "creation_timestamp": model_version.creation_timestamp,
                    "last_updated_timestamp": model_version.last_updated_timestamp,
                    "description": model_version.description,
                    "tags": {}
                }
            }
    
    def _extract_feature_names(self) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω —Ñ–∏—á–µ–π –∏–∑ –º–æ–¥–µ–ª–∏"""
        
        try:
            # –î–ª—è scikit-learn –º–æ–¥–µ–ª–µ–π
            if hasattr(self.model, '_model_impl') and hasattr(self.model._model_impl, 'feature_names_in_'):
                return list(self.model._model_impl.feature_names_in_)
            
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ–∏—á–µ–π
            return [
                "amount", "merchant_category", "hour_of_day", 
                "day_of_week", "user_age", "location_risk_score"
            ]
            
        except Exception as e:
            logger.warning(f"Could not extract feature names: {e}")
            return ["feature_" + str(i) for i in range(6)]  # Default features
    
    def _estimate_model_size(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –≤ MB"""
        try:
            # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é
            with tempfile.NamedTemporaryFile() as tmp:
                pickle.dump(self.model, tmp)
                size_bytes = tmp.tell()
                return round(size_bytes / (1024 * 1024), 2)
        except:
            return 0.0
    
    async def predict(self, transaction_data: pd.DataFrame) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        
        Args:
            transaction_data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if not self.is_loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")
        
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            processed_data = self._preprocess_data(transaction_data)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            start_time = time.time()
            prediction = await asyncio.get_event_loop().run_in_executor(
                None,
                self.model.predict,
                processed_data
            )
            prediction_time = time.time() - start_time
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            try:
                probabilities = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.model.predict_proba,
                    processed_data
                )
                fraud_probability = float(probabilities[0][1])  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ "fraud"
            except:
                # Fallback: –µ—Å–ª–∏ predict_proba –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                fraud_probability = float(prediction[0]) if prediction[0] in [0, 1] else 0.5
            
            is_fraud = bool(prediction[0]) if len(prediction) > 0 else fraud_probability > 0.5
            
            return {
                "is_fraud": is_fraud,
                "fraud_probability": fraud_probability,
                "prediction_time_ms": round(prediction_time * 1000, 2),
                "model_version": self.model_version,
                "features_used": list(processed_data.columns)
            }
            
        except Exception as e:
            log_error(
                error_type="PredictionError",
                error_message=f"Prediction failed: {str(e)}",
                context={"transaction_data": transaction_data.to_dict()},
                exception=e
            )
            raise
    
    async def predict_batch(self, transactions_data: pd.DataFrame) -> pd.DataFrame:
        """
        Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        
        Args:
            transactions_data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        if not self.is_loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")
        
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            processed_data = self._preprocess_data(transactions_data)
            
            # Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            start_time = time.time()
            predictions = await asyncio.get_event_loop().run_in_executor(
                None,
                self.model.predict,
                processed_data
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            try:
                probabilities = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.model.predict_proba,
                    processed_data
                )
                fraud_probabilities = probabilities[:, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ "fraud"
            except:
                fraud_probabilities = predictions.astype(float)
            
            prediction_time = time.time() - start_time
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            results = pd.DataFrame({
                "is_fraud": predictions.astype(bool),
                "fraud_probability": fraud_probabilities,
                "prediction_time_ms": round(prediction_time * 1000 / len(transactions_data), 2),
                "model_version": self.model_version
            })
            
            return results
            
        except Exception as e:
            log_error(
                error_type="BatchPredictionError", 
                error_message=f"Batch prediction failed: {str(e)}",
                context={"batch_size": len(transactions_data)},
                exception=e
            )
            raise
    
    def _preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        processed = data.copy()
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        if 'user_age' in processed.columns:
            processed['user_age'] = processed['user_age'].fillna(35)  # –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç
        
        if 'location_risk_score' in processed.columns:
            processed['location_risk_score'] = processed['location_risk_score'].fillna(0.5)
        
        # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        if 'merchant_category' in processed.columns:
            # –ü—Ä–æ—Å—Ç–æ–µ ordinal encoding –¥–ª—è –¥–µ–º–æ
            category_map = {
                'grocery': 0, 'gas_station': 1, 'restaurant': 2,
                'retail': 3, 'online': 4, 'electronics': 5,
                'pharmacy': 6, 'other': 7
            }
            processed['merchant_category'] = processed['merchant_category'].map(
                lambda x: category_map.get(x, 7)
            )
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —á–∏—Å–ª–æ–≤—ã–µ
        numeric_columns = ['amount', 'merchant_category', 'hour_of_day', 'day_of_week']
        if 'user_age' in processed.columns:
            numeric_columns.append('user_age')
        if 'location_risk_score' in processed.columns:
            numeric_columns.append('location_risk_score')
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ float
        processed = processed[numeric_columns].astype(float)
        
        return processed
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        return {
            "model_name": self.model_name,
            "model_version": self.model_version,
            "model_alias": self.model_alias,
            "is_loaded": self.is_loaded,
            "load_time_ms": self.load_time,
            "feature_names": self.feature_names,
            "metadata": self.model_metadata
        }
