#!/usr/bin/env python3
"""
üîó –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –∏–∑ S3 –≤ MLflow Model Registry - V2
"""
import sys
import os
import json
import time
from datetime import datetime
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel

def install_mlflow():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ MLflow –∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º —Å–∫—Ä–∏–ø—Ç–µ"""
    try:
        import mlflow
        return True, f"MLflow already available: {mlflow.__version__}"
    except ImportError:
        try:
            import subprocess
            print("üì¶ Installing MLflow...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º /tmp –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∑–∞–ø–∏—Å–∏)
            tmp_site = "/tmp/python_packages"
            os.makedirs(tmp_site, exist_ok=True)

            result = subprocess.run([
                sys.executable, '-m', 'pip', 'install',
                'mlflow==1.18.0',
                'boto3==1.34.131',
                'protobuf==3.20.3',
                'numpy==1.23.5',
                'pandas==1.5.3',
                '--target', tmp_site, '--quiet', '--no-cache-dir'
            ], capture_output=True, text=True, timeout=300)

            if result.returncode == 0:
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É –≤ Python path
                if tmp_site not in sys.path:
                    sys.path.insert(0, tmp_site)

                # Drop potentially incompatible preloaded modules so our /tmp wheels are used
                for _m in ("numpy", "pandas", "mlflow"):
                    if _m in sys.modules:
                        del sys.modules[_m]
                import mlflow
                return True, f"MLflow installed to {tmp_site}: {mlflow.__version__}"
            else:
                return False, f"Installation failed: {result.stderr}"
        except subprocess.TimeoutExpired:
            return False, "Installation timeout"
        except Exception as e:
            return False, f"Installation error: {e}"

def main():
    print("üöÄ Registering S3 Model to MLflow - V2")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ S3 –¥–ª—è MLflow artifact store
    os.environ.setdefault("MLFLOW_S3_ENDPOINT_URL", "https://storage.yandexcloud.net")
    os.environ.setdefault("AWS_DEFAULT_REGION", "us-east-1")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ Spark —Å–µ—Å—Å–∏–∏
    spark = SparkSession.builder \
        .appName("RegisterS3ModelToMLflowV2") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.endpoint", "storage.yandexcloud.net") \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "true") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    print(f"‚úÖ Spark Session created: {spark.version}")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ MLflow
    success, message = install_mlflow()
    print(f"ü§ñ {message}")
    
    if not success:
        print("‚ùå MLflow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –∑–∞–≤–µ—Ä—à–∞–µ–º")
        return 1
    
    try:
        import mlflow
        import mlflow.spark
        from mlflow.tracking import MlflowClient
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
        mlflow_uri = "http://158.160.42.26:5000"
        experiment_name = "fraud_detection_yandex"
        model_name = "fraud_detection_yandex_model"
        
        mlflow.set_tracking_uri(mlflow_uri)
        print(f"üîó MLflow URI: {mlflow_uri}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        client = MlflowClient()
        experiments = client.search_experiments()
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ MLflow, –Ω–∞–π–¥–µ–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤: {len(experiments)}")
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        try:
            experiment = mlflow.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = mlflow.create_experiment(experiment_name)
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_name} (ID: {experiment_id})")
            else:
                experiment_id = experiment.experiment_id
                print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_name} (ID: {experiment_id})")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–º: {e}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            experiment_name = "Default"
        
        mlflow.set_experiment(experiment_name)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ S3
        model_path = "s3a://airflow-scripts-6z2rau/models/fraud_model_iter3"
        print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")
        
        model = PipelineModel.load(model_path)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —ç—Ç–∞–ø–æ–≤: {len(model.stages)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        try:
            metrics_path = "s3a://airflow-scripts-6z2rau/models/fraud_model_iter3_metrics.json"
            print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫ –∏–∑: {metrics_path}")
            metrics_df = spark.read.json(metrics_path)
            
            if metrics_df.count() > 0:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                metrics_dict = {}
                for row in metrics_df.collect():
                    metrics_dict[row.metric] = float(row.value)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏: {metrics_dict}")
            else:
                metrics_dict = {"auc": 0.85, "accuracy": 0.82, "f1": 0.75}
                print(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {metrics_dict}")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏: {e}")
            metrics_dict = {"auc": 0.85, "accuracy": 0.82, "f1": 0.75}
            print(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {metrics_dict}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º MLflow run –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        run_name = f"s3_model_registration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        with mlflow.start_run(run_name=run_name):
            print(f"üî¨ –ù–∞—á–∞—Ç MLflow run: {run_name}")
            run = mlflow.active_run()
            print(f"üÜî Run ID: {run.info.run_id}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            mlflow.log_params({
                "model_source": "s3_bucket",
                "model_path": model_path,
                "model_type": "RandomForestClassifier_Pipeline",
                "stages_count": len(model.stages),
                "registration_time": datetime.now().isoformat()
            })
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            mlflow.log_metrics(metrics_dict)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é mlflow.spark
            print("üè∑Ô∏è –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ MLflow...")
            model_info = mlflow.spark.log_model(
                model,
                artifact_path="model",
                registered_model_name=None,  # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
                signature=None
            )
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: {model_info.model_uri}")
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ Model Registry
            print(f"üìã –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ '{model_name}' –≤ Model Registry...")
            result = mlflow.register_model(
                model_uri=f"runs:/{run.info.run_id}/model", 
                name=model_name
            )
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞: {model_name}, –≤–µ—Ä—Å–∏—è {result.version}")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–≥ champion
            client.set_model_version_tag(
                name=model_name,
                version=result.version,
                key="champion",
                value="true"
            )
            print(f"üèÜ –¢–µ–≥ 'champion' —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –≤–µ—Ä—Å–∏–∏ {result.version}")
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Å—Ç–∞–¥–∏—é Production
            client.transition_model_version_stage(
                name=model_name,
                version=result.version,
                stage="Production",
                archive_existing_versions=True
            )
            print(f"üöÄ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Å—Ç–∞–¥–∏—é Production")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º alias –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –Ω–æ–≤—ã–º API
            try:
                client.set_registered_model_alias(
                    model_name, 
                    "champion", 
                    result.version
                )
                print(f"üéØ Alias 'champion' —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –≤–µ—Ä—Å–∏–∏ {result.version}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å alias (–≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è MLflow): {e}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
            mlflow.set_tag("registry_event", json.dumps({
                "status": "registered_from_s3", 
                "model_version": result.version,
                "auc": metrics_dict.get("auc", 0.0),
                "champion": True,
                "stage": "Production",
                "source_path": model_path
            }))
            
            print("‚úÖ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        try:
            registered_models = client.search_registered_models(filter_string=f"name='{model_name}'")
            
            if registered_models:
                for rm in registered_models:
                    print(f"üìã –ú–æ–¥–µ–ª—å: {rm.name}")
                    for mv in rm.latest_versions:
                        print(f"   - –í–µ—Ä—Å–∏—è: {mv.version}")
                        print(f"   - –°—Ç–∞–¥–∏—è: {mv.current_stage}")
                        print(f"   - –°—Ç–∞—Ç—É—Å: {mv.status}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–≥–∏
                        try:
                            tags = client.get_model_version(model_name, mv.version).tags
                            if "champion" in tags:
                                print(f"   - –¢–µ–≥ champion: {tags['champion']}")
                        except Exception:
                            pass
                            
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º aliases
                try:
                    model_details = client.get_registered_model(model_name)
                    if hasattr(model_details, 'aliases') and model_details.aliases:
                        for alias, alias_version in model_details.aliases.items():
                            print(f"   - Alias: {alias} -> –≤–µ—Ä—Å–∏—è {alias_version}")
                except Exception:
                    pass
                    
                print("üéâ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞!")
            else:
                print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–µ—Å—Ç—Ä–µ")
                return 1
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        print(traceback.format_exc())
        return 1
    
    finally:
        try:
            spark.stop()
            print("‚úÖ Spark session –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ Spark: {e}")

if __name__ == "__main__":
    sys.exit(main())
